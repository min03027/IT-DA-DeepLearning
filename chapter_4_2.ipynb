{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ad8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train),(x_test, t_test) = load_mnist(flatten=True, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d58239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d7d556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train,t_train),(x_test,t_test) = \\\n",
    "    load_mnist(normalize = True, one_hot_label=True)\n",
    "  \n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9bfa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size,batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c563e68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7725, 22517,  7110, 20493, 35986, 51314, 29533, 29612, 12560,\n",
       "       37292])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639c807",
   "metadata": {},
   "source": [
    "전체 훈련 데이터의 대표로서 무작위로 선택한 작은 덩어리(미니배치)를 사용하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e3d24",
   "metadata": {},
   "source": [
    "#.4.2.4(배치용)교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e75f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t* np.log(y+1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff783fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim ==1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t]+ 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db551a3",
   "metadata": {},
   "source": [
    "#4.2.5 왜 손실 함수를 설정하는가?\n",
    "신경망을 학습할 땨 정확도를 지표로 삼아서는 안 된다. 정확도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다. 따라서 가중치 매개변수의 값을 변화 시켜 손실함수를 변화 시키는데, 이때 이 미분 값이 음수면 가중치 매개변수를 양의 방향으로 변화시켜 손실함수의 값을 줄일 수 있고, 미분값이 양수면 가중치 매개변수를 음의 방향으로 변화시켜 손실함수의 값을 줄일 수 있다.\n",
    "\n",
    "손실함수를 지표로 삼으면 매개변수가 조금 변할때에 손실함수의 값도 연속적으로 변화한다.\n",
    "\n",
    "정확도를 지표로 삼지 않는 이유는 계단함수를 사용하지 않는 이유와 비슷한데, 계단함수의 미분은 대부분의 장소에서 0 이고, 이는 손실함수를 지표로 삼는게 의미 없어진다. 따라서 매개 변수의 작은 변화가 주는 파장을 계단함수가 말살하여 손실함수의 값에는 아무런 변화가 나타나지 않기 때문이다. \n",
    "\n",
    "계단함수는 한순간만 변화를 일으키지만, 시그모이드 함수는 출력이 연속적으로 변하고 곡선의 기울기도 연속적으로 변한다.\n",
    "\n",
    "즉 시그모이드 함수는 어느 장소라도 0이 되지는 않는다. 이는 신경망 학습에서 중요한 성질로, 기울기가 0이 되지 않는 덕분에 신경망이 올바르게 학습할 수 있는 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
